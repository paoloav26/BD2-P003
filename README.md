# BD2-P003 Facial Recognition üòé

## Integrantes üôã‚Äç‚ôÇÔ∏è
- Matias Avenda√±o Vargas  [Matias222]
- Paolo Armas Vega [Paoloav26]

## Profesor ü¶æ
- Heider Sanchez Enriquez

## Objetivos Principales üéØ
- Este proyecto est√° enfocado al uso una estructura multidimensional para dar soporte a las b√∫squeda y 
recuperaci√≥n eficiente de im√°genes en un servicio web de reconocimiento facial.

## Comenzando üöÄ
### Pre-requisitos üìã
- Python >= 3.8
### Despliegue üì¶
 Crear en server, una carpeta de nombre "static" en ella agregar la dataset (http://vis-www.cs.umass.edu/lfw/), no la podimos subir al presente git por el peso del archivo. <br />
- Ejecutar archivo __init__.py de la carpeta server
### Dataset
- El conjunto de fotograf√≠as del laboratorio 11 que consta de 13233 im√°genes de 5749 personas distintas.
### Librer√≠as empleadas
-Pickle: Facilita el guardado de diccionarios en memoria secundaria, esto lo empleamos para extraer los vectores caracter√≠sticos del dataset s√≥lo una vez. <br />

-Face Recognition: Permite la extracci√≥n de los vectores caracter√≠sticos de cada fotograf√≠a, estos son 128 dimensional. <br />

-Rtree: Genera el √≠ndice Rtree en memoria secundaria, contiene una funci√≥n que devuelve los K elementos m√°s cercanos a una query.  <br />

-Faiss: √çndice multidimensional eficiente, entre sus distinciones con otros algoritmos el uso de multithreading a nivel de GPU, el uso de BLAS (Basic Linear Algebra Subprogram) para el c√≥mputo de las distancias y vectorizaci√≥n SIMD 

### M√©todos
-Computamos para toda la dataset los vectores caracter√≠sticos y los guardamos en memoria secundaria a trav√©s de Pickle, esto con el objetivo de no voler a realizar ese c√°lculo tan costoso, posteriormente realizamos las consultas a KNNheap, KNNRtree y KNNHigh, a excepci√≥n de la primera funci√≥n (que consta de calcular las distancias euclidianas entre la consulta y toda la dataset) los dem√°s m√©todos en sus librer√≠as respectivas ya facilitan los K vecinos m√°s cercanos.

### Maldici√≥n de la dimensionalidad
-Trabajamos con 128 dimensiones, para lo cual no hemos encontrado esparcidad en nuestras respuestas, sin embargo, hemos notado como observaremos en experimentaci√≥n que probablemente se pueda aumentar aun m√°s el tama√±o del vector latente, no obstante, si hallamos un gran incoveniente en los tiempos de c√≥mputo, esto se puede reducir mediante una t√©cnica de reducci√≥n de la dimensionalidad como PCA pero el problema de aplicar eso es que perderiamos c√°lidad en las respuestas.

### Experimentaci√≥n
